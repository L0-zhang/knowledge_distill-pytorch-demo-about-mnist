{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_kd.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNzJ9vu4gfijfVflbwu7C/L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cv-ape/mnist-knowledge_distillation-pytorch-demo/blob/main/mnist_kd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzW2jbHlmXLB"
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r90o7Ui5Ovy",
        "outputId": "d178ded0-e3f7-479a-eba3-fa2bab7af561"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "prj=\"knowledge_distill\"\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/\"+prj"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmtt8PC5pjSx"
      },
      "source": [
        "class config:\n",
        "  batch_size=128 #input batch size for training\n",
        "  test_batch_size=1000 #input batch size for testing\n",
        "  epochs=5 #number of epochs to train\n",
        "  lr=0.01 #learning rate\n",
        "  momentum=0.9 #SGD momentum\n",
        "  no_cuda=False #disables CUDA training\n",
        "  seed=1 #random seed \n",
        "  log_interval=10#how many batches to wait before logging training status\n",
        "  device='cuda' if (not no_cuda and torch.cuda.is_available()) else 'cpu'\n",
        "cfg=config()\n",
        "device=cfg.device\n",
        "torch.manual_seed(cfg.seed)\n",
        "if device=='cuda' :\n",
        "    torch.cuda.manual_seed(cfg.seed)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvKghUjGpeG4"
      },
      "source": [
        "dataset loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ni9YkjVpKMq"
      },
      "source": [
        "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./data_mnist', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=cfg.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./data_mnist', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=cfg.test_batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDXqHqZspcno"
      },
      "source": [
        "教师网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBYpPbbjmmtP"
      },
      "source": [
        "class teacherNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(teacherNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 1200)\n",
        "        self.fc2 = nn.Linear(1200, 1200)\n",
        "        self.fc3 = nn.Linear(1200, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, p=0.8, training=self.training)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.dropout(x, p=0.8, training=self.training)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNaFOLO8xrTl"
      },
      "source": [
        "def train_Teacher(epoch, model):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        #data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % cfg.log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vF5c8Hioj6e"
      },
      "source": [
        "def train_evaluate(model):\n",
        "    model.eval()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in train_loader:\n",
        "        with torch.no_grad():\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          output = model(data)\n",
        "        train_loss += F.cross_entropy(output, target).item() # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        train_loss, correct, len(train_loader.dataset),\n",
        "        100. * correct / len(train_loader.dataset)))\n",
        "\n",
        "\n",
        "def test(model):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        with torch.no_grad():\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          output = model(data)\n",
        "        test_loss += F.cross_entropy(output, target).item() # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MeTPO1Kv6Hao",
        "outputId": "9c466ee5-a2b7-4fb8-db98-ee9dcda915a9"
      },
      "source": [
        "path+\"/teacher_MLP.pth.tar\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/knowledge_distill/teacher_MLP.pth.tar'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMV204UapXPt"
      },
      "source": [
        "训练教师网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w72xlJowol0Y",
        "outputId": "0f428df8-227d-47b6-bc9e-a3a09f312a71"
      },
      "source": [
        "teacher_model = teacherNet()\n",
        "teacher_model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(teacher_model.parameters(), lr=cfg.lr, momentum=cfg.momentum,\n",
        "                      weight_decay=5e-4)\n",
        "\n",
        "if os.path.exists(path+\"/teacher_MLP.pth.tar\"):\n",
        "  teacher_model.load_state_dict(torch.load(path+'/teacher_MLP.pth.tar',map_location=device))\n",
        "  print(\"existed weight is loaded!\")\n",
        "\n",
        "for epoch in range(1, cfg.epochs + 1):\n",
        "    train_Teacher(epoch, teacher_model)\n",
        "    train_evaluate(teacher_model)\n",
        "    test(teacher_model)\n",
        "#torch.save(teacher_model.state_dict(), 'teacher_MLP.pth.tar')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "existed weight is loaded!\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.141338\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.192521\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.104673\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.315151\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.104542\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.137927\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.208151\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.198235\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.327017\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.120329\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.165555\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.162400\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.187118\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.172194\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.225501\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.159121\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.190122\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.098143\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.109893\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.260673\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.181389\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.093047\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.212428\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.191213\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.226660\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.158992\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.213744\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.122105\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.173320\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.368209\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.157921\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.149419\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.277024\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.340170\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.159349\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.242895\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.255878\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.148725\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.113856\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.184422\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.223823\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.339631\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.139512\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.060535\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.255547\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.178699\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.316773\n",
            "\n",
            "Train set: Average loss: 38.1411, Accuracy: 58604/60000 (98%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9719/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.225848\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.114684\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.112622\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.177571\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.288231\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.170472\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.128372\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.221258\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.176537\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.129650\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.154433\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.199844\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.328089\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.124237\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.168787\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.135705\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.304312\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.065387\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.104233\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.260161\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.114925\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.261006\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.185321\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.293545\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.153330\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.186016\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.167635\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.184569\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.108005\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.114483\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.133568\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.210598\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.088401\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.167480\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.405433\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.114344\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.280900\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.199984\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.287418\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.145445\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.278168\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.117099\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.077634\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.097514\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.149081\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.175482\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.178458\n",
            "\n",
            "Train set: Average loss: 35.0719, Accuracy: 58667/60000 (98%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9717/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.190810\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.122127\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.101812\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.131327\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.218985\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.233918\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.084415\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.078349\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.290310\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.036663\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.094547\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.095309\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.202122\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.075955\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.097096\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.214009\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.100892\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.052540\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.170380\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.105499\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.224508\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.217543\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.100350\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.051466\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.107200\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.206361\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.113058\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.123850\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.225682\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.158268\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.199673\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.156052\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.078548\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.102788\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.203454\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.199608\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.123846\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.179835\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.286684\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.126728\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.123105\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.157647\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.191506\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.193886\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.144561\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.104715\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.104544\n",
            "\n",
            "Train set: Average loss: 32.1289, Accuracy: 58815/60000 (98%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9742/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.237706\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.343886\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.167894\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.212386\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.128177\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.087061\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.076179\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.114488\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.191533\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.224136\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.110921\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.119088\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.082668\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.088998\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.160631\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.083977\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.070115\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.175089\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.197899\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.133013\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.130485\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.090537\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.082421\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.098375\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.083435\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.216578\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.097250\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.173616\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.087326\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.117410\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.167053\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.309863\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.099945\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.183387\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.243871\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.211222\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.258078\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.096223\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.157270\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.177592\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.250538\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.077220\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.209296\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.075702\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.102350\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.110626\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.160256\n",
            "\n",
            "Train set: Average loss: 30.8555, Accuracy: 58841/60000 (98%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9736/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.070335\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.161597\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.054873\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.145345\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.219012\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.105084\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.097445\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.071361\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.088837\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.200064\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.158667\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.093053\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.304319\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.183967\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.210997\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.161576\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.076690\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.112535\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.143900\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.129892\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.122400\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.239935\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.100474\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.209551\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.148932\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.182113\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.132546\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.230959\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.092688\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.087752\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.175734\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.107581\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.136019\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.093258\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.234894\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.086092\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.079389\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.135969\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.132405\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.118738\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.246821\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.174894\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.251608\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.112152\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.176147\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.208816\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.115502\n",
            "\n",
            "Train set: Average loss: 29.4283, Accuracy: 58887/60000 (98%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9751/10000 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETUhvTpLsPHx"
      },
      "source": [
        "torch.save(teacher_model.state_dict(), path+'/teacher_MLP.pth.tar')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri6Oli4tmpDo"
      },
      "source": [
        "class studentNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(studentNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 800)\n",
        "        self.fc2 = nn.Linear(800, 800)\n",
        "        self.fc3 = nn.Linear(800, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs4mNsuemuZg"
      },
      "source": [
        "def distill_unlabeled(outputs,labels, teacher_scores):\n",
        "    alpha=0.8\n",
        "    T=2\n",
        "    return nn.KLDivLoss()(F.log_softmax(outputs/T), F.softmax(teacher_scores/T)) * (alpha * T * T) + \\\n",
        "              F.cross_entropy(outputs, labels) * (1. - alpha)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCe6CjcPmwM_"
      },
      "source": [
        "def train_student(epoch, model, loss_fn):\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    teacher_model.eval()\n",
        "    teacher_model.to(device)\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        teacher_output = teacher_model(data).detach()\n",
        "        loss = loss_fn(output,target, teacher_output)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % cfg.log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKl9mmBKvAO1"
      },
      "source": [
        "训练学生网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs4_rWqcnOa4"
      },
      "source": [
        "teacher_model = teacherNet()\n",
        "teacher_model.load_state_dict(torch.load('teacher_MLP.pth.tar',map_location=device))\n",
        "\n",
        "student_model = studentNet()\n",
        "student_model.to(device)\n",
        "\n",
        "optimizer =optim.SGD(student_model.parameters(), lr=cfg.lr, momentum=cfg.momentum)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-co52GRBnQQh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed732587-b346-4fbb-abaf-2b15ea12b04a"
      },
      "source": [
        "for epoch in range(1, cfg.epochs + 1):\n",
        "    train_student(epoch, student_model, loss_fn=distill_unlabeled)\n",
        "    train_evaluate(student_model)\n",
        "    test(student_model)\n",
        "\n",
        "torch.save(student_model.state_dict(), 'distill_unlabeled.pth.tar')\n",
        "# the_model = Net()\n",
        "# the_model.load_state_dict(torch.load('student.pth.tar'))\n",
        "\n",
        "# test(the_model)\n",
        "# for data, target in test_loader:\n",
        "#     data, target = Variable(data, volatile=True), Variable(target)\n",
        "#     teacher_out = the_model(data)\n",
        "# print(teacher_out)\n",
        "#print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2611: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.083729\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 1.062772\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.976162\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.889226\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.850043\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.658848\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.537973\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.430115\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.362441\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.295150\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.229341\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.268541\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.177605\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.177284\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.242263\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.205933\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.184633\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.166083\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.150047\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.187602\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.146420\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.208471\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.100207\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.133326\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.155914\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.160273\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.153586\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.175545\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.157896\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.109468\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.115617\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.130145\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.168907\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.118753\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.099288\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.143552\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.136426\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.111461\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.088252\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.113939\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.155706\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.127168\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.128968\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.120521\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.071935\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.092605\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.086724\n",
            "\n",
            "Train set: Average loss: 130.6064, Accuracy: 55023/60000 (92%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0003, Accuracy: 9228/10000 (92%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.090305\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.093651\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.091827\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.071364\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.096658\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.095934\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.073612\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.110925\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.075230\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.077223\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.133431\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.107847\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.065036\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.073946\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.078042\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.066029\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.092407\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.101354\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.095698\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.088498\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.066146\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.093121\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.107777\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.047559\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.118193\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.101726\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.075915\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.067471\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.058777\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.072498\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.054812\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.067927\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.074672\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.050467\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.069100\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.071719\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.079372\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.074608\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.075298\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.040885\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.088453\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.094390\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.057225\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.044117\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.070642\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.057922\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.110012\n",
            "\n",
            "Train set: Average loss: 90.6212, Accuracy: 56577/60000 (94%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0002, Accuracy: 9425/10000 (94%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.098086\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.050489\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.068914\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.042761\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.060858\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.044599\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.089143\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.048195\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.043093\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.054131\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.104712\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.042308\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.064512\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.083359\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.055822\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.047801\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.068385\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.091653\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.054536\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.062999\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.049852\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.056614\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.061310\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.074954\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.054781\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.026198\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.041107\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.065189\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.048803\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.030513\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.062371\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.046772\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.047959\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.038738\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.043056\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.053505\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.056308\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.055383\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.061172\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.038289\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.041634\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.078624\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.041549\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.034540\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.063785\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.047956\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.046364\n",
            "\n",
            "Train set: Average loss: 67.5664, Accuracy: 57390/60000 (96%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9546/10000 (95%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.035830\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.064671\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.052473\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.038089\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.044084\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.032971\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.029459\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.039611\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.054167\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.051941\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.032295\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.052570\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.068762\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.058395\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.048628\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.030277\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.040871\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.052688\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.057965\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.034520\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.065747\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.039742\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.026963\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.035772\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.042967\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.037407\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.040578\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.047895\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.039786\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.028093\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.031085\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.031085\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.040162\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.043324\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.032867\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.050696\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.033466\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.036717\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.036473\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.037130\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.029974\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.056450\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.048393\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.044018\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.028342\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.039015\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.045922\n",
            "\n",
            "Train set: Average loss: 55.6160, Accuracy: 57847/60000 (96%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9612/10000 (96%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.035723\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.033643\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.038383\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.031719\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.027332\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.043291\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.021592\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.052647\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.024124\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.028602\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.039124\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.030380\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.039430\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.022277\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.030415\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.030874\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.025665\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.041590\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.039765\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.020121\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.030209\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.024995\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.047518\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.030420\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.041216\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.027934\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.041171\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.039940\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.025534\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.013887\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.038006\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.033686\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.028409\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.043623\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.043041\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.020419\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.044857\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.027378\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.030092\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.046290\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.031319\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.019794\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.059613\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.030890\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.029188\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.036622\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.033457\n",
            "\n",
            "Train set: Average loss: 47.1102, Accuracy: 58172/60000 (97%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0001, Accuracy: 9654/10000 (97%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
